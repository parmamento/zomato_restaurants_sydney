{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ecb9381",
   "metadata": {},
   "source": [
    "<h2 style='text-align: center;'> Data Science Technology and Systems </h2>\n",
    "<h3 style='text-align: center;'> Assignment 1: Predictive Modelling of Eating-Out Problem </h3>\n",
    "<h3 style='text-align: center;'> Part B - Predictive Modelling </h3>\n",
    "<h4 style='text-align: center;'> Pauline Armamento - u3246782 </h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a39a0516",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "This project aims to leverage a real-world dataset comprising over 10,000 Sydney restaurants from 2018 to predict restaurant ratings. The objective of this project is to conduct a comprehensive Exploratory Data Analysis (EDA), feature engineering, develop regression and classification models, and demonstrate practical deployment skills. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54aa406b",
   "metadata": {},
   "source": [
    "### The following libraries were used to retrieve, explore, process and present data within the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ef18d760",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\pauar\\\\Desktop\\\\UC\\\\DSTS\\\\DSTS Assignment'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import ast\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2894d896",
   "metadata": {},
   "source": [
    "## Exploring Data\n",
    "\n",
    "### Data Description\n",
    "\n",
    "The dataframe is comprised of 10,500 data entries with 17 columns ['address', 'cost', 'cuisine', 'lat', 'link', 'lng', 'phone', 'rating_number', 'rating_text', 'subzone', 'title', 'type', 'votes', 'groupon', 'color', 'cost_2', 'cuisine_color']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4cd7d96",
   "metadata": {},
   "source": [
    "### Read Zomato Restaurant Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e65ad01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame: zomato_df_final_data\n",
      "Number of rows: 10500\n",
      "Column names: ['address', 'cost', 'cuisine', 'lat', 'link', 'lng', 'phone', 'rating_number', 'rating_text', 'subzone', 'title', 'type', 'votes', 'groupon', 'color', 'cost_2', 'cuisine_color']\n"
     ]
    }
   ],
   "source": [
    "# Define the directory path\n",
    "\n",
    "df = pd.read_csv(\"data/zomato_df_final_data.csv\")\n",
    "\n",
    "print(\"DataFrame: zomato_df_final_data\")\n",
    "print(\"Number of rows:\", df.shape[0])\n",
    "print(\"Column names:\", df.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cecf4e4",
   "metadata": {},
   "source": [
    "To understand the contents of our dataframe, we want to look at what data types are present in each columnn. This information will be essential in guiding us for subsequent processing and task analysis within this assignment.\n",
    "\n",
    "Here we observed a combination of numerical and categorical features that will be further processed for quantitative analysis and modeling. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6578786b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "address           object\n",
       "cost             float64\n",
       "cuisine           object\n",
       "lat              float64\n",
       "link              object\n",
       "lng              float64\n",
       "phone             object\n",
       "rating_number    float64\n",
       "rating_text       object\n",
       "subzone           object\n",
       "title             object\n",
       "type              object\n",
       "votes            float64\n",
       "groupon             bool\n",
       "color             object\n",
       "cost_2           float64\n",
       "cuisine_color     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check data types\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "482d1030",
   "metadata": {},
   "source": [
    "#### Verify Column Contents\n",
    "\n",
    "In addition to examining the data types, we wanted to see the degree of categories for specified columns ['subzone', 'cuisine', 'title', 'type']. This gives us an idea about the distributions of these categories that can provide insights to the restaurant landscape in Sydney."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4bfe9999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contents of column 'subzone':\n",
      "CBD                                         476\n",
      "Surry Hills                                 260\n",
      "Parramatta                                  225\n",
      "Darlinghurst                                188\n",
      "Chinatown                                   174\n",
      "                                           ... \n",
      "The Sydney Boulevard Hotel, Darlinghurst      1\n",
      "Pullman Quay Grand Sydney Harbour, CBD        1\n",
      "Chullora                                      1\n",
      "Marriott Sydney Harbour, Circular Quay        1\n",
      "Holiday Inn Old Sydney, The Rocks             1\n",
      "Name: subzone, Length: 572, dtype: int64\n",
      "\n",
      "Contents of column 'cuisine':\n",
      "['Cafe']                                   1745\n",
      "['Thai']                                    542\n",
      "['Chinese']                                 450\n",
      "['Modern Australian']                       346\n",
      "['Indian']                                  286\n",
      "                                           ... \n",
      "['Cafe', 'Spanish', 'Italian', 'Tapas']       1\n",
      "['Desserts', 'Steak', 'Tapas']                1\n",
      "['Pub Food', 'Burger', 'Pizza']               1\n",
      "['Cambodian', 'Vietnamese']                   1\n",
      "['Kebab', 'Burger', 'Fish and Chips']         1\n",
      "Name: cuisine, Length: 1759, dtype: int64\n",
      "\n",
      "Contents of column 'title':\n",
      "Royal Hotel                     5\n",
      "King of Kebabs                  4\n",
      "Charcoal Chicken                3\n",
      "Lucie's Cafe                    2\n",
      "The Loft                        2\n",
      "                               ..\n",
      "Mootch & Me                     1\n",
      "The House of Herbs and Roses    1\n",
      "Po Po Hurstville                1\n",
      "Hurstville Chinese              1\n",
      "O'Siam                          1\n",
      "Name: title, Length: 10407, dtype: int64\n",
      "\n",
      "Contents of column 'type':\n",
      "['Casual Dining']                    4854\n",
      "['Café']                             2767\n",
      "['Fast Food']                         557\n",
      "['Food Court']                        480\n",
      "['Pub']                               284\n",
      "                                     ... \n",
      "['Club', 'Casual Dining']               1\n",
      "['Dessert Parlour', 'Fast Food']        1\n",
      "['Dessert Parlour', 'Food Court']       1\n",
      "['Club', 'Pub']                         1\n",
      "['Food Court', 'Beverage Shop']         1\n",
      "Name: type, Length: 66, dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define columns to check contents\n",
    "columns_to_check = ['subzone', 'cuisine', 'title', 'type']\n",
    "\n",
    "# Print Column Contents\n",
    "for column in columns_to_check:\n",
    "    print(f\"Contents of column '{column}':\")\n",
    "    print(df[column].value_counts())\n",
    "    print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5233c2e",
   "metadata": {},
   "source": [
    "## I. Feature Engineering\n",
    "\n",
    "Feature engineering as discussed in the DSTS lectures is the process of transforming variables or features from the raw data and making them suitable for the data modelling process. In this part of the assignment we implement feature engineering approaches for the following tasks:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "347ff6e4",
   "metadata": {},
   "source": [
    "### 1. Perform data cleaning to remove/impute any useless records in the predictive task (such as NA, NaN, etc.)\n",
    "\n",
    "As we have seen in Assignment Part A, there were missing values in the dataframe where we set aside to resolve in this Part B. We initially show the items containing missing values in the dataframe. Given some data entries where we cannot impute missing values, we removed these data within columns (lat, lng, type, votes, cost_2) and impute missing values where we can utilise mean for numeric columns such as cost an rating number. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61b8a092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost              346\n",
      "lat               192\n",
      "lng               192\n",
      "rating_number    3316\n",
      "rating_text      3316\n",
      "type               48\n",
      "votes            3316\n",
      "cost_2            346\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "missing_values = df.isnull().sum()\n",
    "print(missing_values[missing_values > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e17dde0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute missing values to fill with mean for cost and rating_number\n",
    "\n",
    "df['cost'] = df['cost'].fillna(df['cost'].mean())\n",
    "df['rating_number'] = df['rating_number'].fillna(df['rating_number'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2eee805d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with missing values\n",
    "\n",
    "df_cleaned = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "78dd446c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values in df_cleaned\n",
    "\n",
    "missing_values_df_cleaned = df_cleaned.isnull().sum()\n",
    "print(missing_values_df_cleaned[missing_values_df_cleaned > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ce7e2162",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Duplicates\n",
    "# As precautionary we also removed potential duplicates in the dataframe\n",
    "\n",
    "df_cleaned = df_cleaned.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a418db3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data types to numeric\n",
    "\n",
    "df_cleaned['cost'] = pd.to_numeric(df_cleaned['cost'], errors='coerce')\n",
    "df_cleaned['rating_number'] = pd.to_numeric(df_cleaned['rating_number'], errors='coerce')\n",
    "df_cleaned['votes'] = pd.to_numeric(df_cleaned['votes'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ce0082cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 6948 entries, 0 to 10212\n",
      "Data columns (total 17 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   address        6948 non-null   object \n",
      " 1   cost           6948 non-null   float64\n",
      " 2   cuisine        6948 non-null   object \n",
      " 3   lat            6948 non-null   float64\n",
      " 4   link           6948 non-null   object \n",
      " 5   lng            6948 non-null   float64\n",
      " 6   phone          6948 non-null   object \n",
      " 7   rating_number  6948 non-null   float64\n",
      " 8   rating_text    6948 non-null   object \n",
      " 9   subzone        6948 non-null   object \n",
      " 10  title          6948 non-null   object \n",
      " 11  type           6948 non-null   object \n",
      " 12  votes          6948 non-null   float64\n",
      " 13  groupon        6948 non-null   bool   \n",
      " 14  color          6948 non-null   object \n",
      " 15  cost_2         6948 non-null   float64\n",
      " 16  cuisine_color  6948 non-null   object \n",
      "dtypes: bool(1), float64(6), object(10)\n",
      "memory usage: 929.6+ KB\n"
     ]
    }
   ],
   "source": [
    "# Print df_cleaned info\n",
    "\n",
    "df_cleaned.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198495eb",
   "metadata": {},
   "source": [
    "### 2. Use proper label/feature encoding for each feature/column you consider, preparing the data for the modelling step.\n",
    "\n",
    "As we have have seen in the previous cell, we have a list of numerical and categorical variables. We then processed the categorical variables such as 'cuisine', 'subzone', 'title', 'type', and 'groupon' for Feature Encoding to prepare the data for modelling. We employed One-Hot Encoding for Nominal Features that transforms categorical variables into binary matrix and Lable Encoding for Ordinal Feature 'rating_text' that converts each nominal feature into a numerical value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cdff0970",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          address  cost     cuisine  \\\n",
      "0                   371A Pitt Street, CBD, Sydney  50.0     Hot Pot   \n",
      "0                   371A Pitt Street, CBD, Sydney  50.0  Korean BBQ   \n",
      "0                   371A Pitt Street, CBD, Sydney  50.0         BBQ   \n",
      "0                   371A Pitt Street, CBD, Sydney  50.0      Korean   \n",
      "1   Shop 7A, 2 Huntley Street, Alexandria, Sydney  80.0        Cafe   \n",
      "\n",
      "         lat                                               link         lng  \\\n",
      "0 -33.876059    https://www.zomato.com/sydney/sydney-madang-cbd  151.207605   \n",
      "0 -33.876059    https://www.zomato.com/sydney/sydney-madang-cbd  151.207605   \n",
      "0 -33.876059    https://www.zomato.com/sydney/sydney-madang-cbd  151.207605   \n",
      "0 -33.876059    https://www.zomato.com/sydney/sydney-madang-cbd  151.207605   \n",
      "1 -33.910999  https://www.zomato.com/sydney/the-grounds-of-a...  151.193793   \n",
      "\n",
      "          phone  rating_number rating_text  \\\n",
      "0  02 8318 0406            4.0   Very Good   \n",
      "0  02 8318 0406            4.0   Very Good   \n",
      "0  02 8318 0406            4.0   Very Good   \n",
      "0  02 8318 0406            4.0   Very Good   \n",
      "1  02 9699 2225            4.6   Excellent   \n",
      "\n",
      "                                 subzone                           title  \\\n",
      "0                                    CBD                   Sydney Madang   \n",
      "0                                    CBD                   Sydney Madang   \n",
      "0                                    CBD                   Sydney Madang   \n",
      "0                                    CBD                   Sydney Madang   \n",
      "1  The Grounds of Alexandria, Alexandria  The Grounds of Alexandria Cafe   \n",
      "\n",
      "                type   votes  groupon    color    cost_2 cuisine_color  \n",
      "0  ['Casual Dining']  1311.0    False  #e15307  5.243902       #6f706b  \n",
      "0  ['Casual Dining']  1311.0    False  #e15307  5.243902       #6f706b  \n",
      "0  ['Casual Dining']  1311.0    False  #e15307  5.243902       #6f706b  \n",
      "0  ['Casual Dining']  1311.0    False  #e15307  5.243902       #6f706b  \n",
      "1           ['Café']  3236.0    False  #9c3203  7.560976       #6f706b  \n"
     ]
    }
   ],
   "source": [
    "# We used explode to split the cuisine to their own individual rows\n",
    "\n",
    "# Convert the 'cuisine' column to string\n",
    "df_cleaned['cuisine'] = df_cleaned['cuisine'].astype(str)\n",
    "\n",
    "# split cuisine column into lists\n",
    "df_cleaned['cuisine'] = df_cleaned['cuisine'].str.replace(r\"[\\[\\]']\", \"\", regex=True).str.split(\", \")\n",
    "\n",
    "# Explode the lists into separate rows\n",
    "df_cleaned_exploded = df_cleaned.explode('cuisine')\n",
    "\n",
    "# Print df_cleaned_exploded\n",
    "print(df_cleaned_exploded.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "43e1aafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features for encoding\n",
    "\n",
    "categorical_features = ['cuisine', 'subzone', 'title', 'type', 'groupon']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "95bb04c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-Hot Encoding for Nominal Features\n",
    "\n",
    "df_encoded = pd.get_dummies(df_cleaned_exploded, columns=categorical_features, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "25ae47f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Encoding for Ordinal Features \n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "df_encoded['rating_text'] = label_encoder.fit_transform(df_encoded['rating_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d97065a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          address  cost        lat  \\\n",
      "0                   371A Pitt Street, CBD, Sydney  50.0 -33.876059   \n",
      "0                   371A Pitt Street, CBD, Sydney  50.0 -33.876059   \n",
      "0                   371A Pitt Street, CBD, Sydney  50.0 -33.876059   \n",
      "0                   371A Pitt Street, CBD, Sydney  50.0 -33.876059   \n",
      "1   Shop 7A, 2 Huntley Street, Alexandria, Sydney  80.0 -33.910999   \n",
      "\n",
      "                                                link         lng  \\\n",
      "0    https://www.zomato.com/sydney/sydney-madang-cbd  151.207605   \n",
      "0    https://www.zomato.com/sydney/sydney-madang-cbd  151.207605   \n",
      "0    https://www.zomato.com/sydney/sydney-madang-cbd  151.207605   \n",
      "0    https://www.zomato.com/sydney/sydney-madang-cbd  151.207605   \n",
      "1  https://www.zomato.com/sydney/the-grounds-of-a...  151.193793   \n",
      "\n",
      "          phone  rating_number  rating_text   votes    color  ...  \\\n",
      "0  02 8318 0406            4.0            4  1311.0  #e15307  ...   \n",
      "0  02 8318 0406            4.0            4  1311.0  #e15307  ...   \n",
      "0  02 8318 0406            4.0            4  1311.0  #e15307  ...   \n",
      "0  02 8318 0406            4.0            4  1311.0  #e15307  ...   \n",
      "1  02 9699 2225            4.6            1  3236.0  #9c3203  ...   \n",
      "\n",
      "   type_['Food Court'] type_['Food Truck']  type_['Pub', 'Bar']  \\\n",
      "0                    0                   0                    0   \n",
      "0                    0                   0                    0   \n",
      "0                    0                   0                    0   \n",
      "0                    0                   0                    0   \n",
      "1                    0                   0                    0   \n",
      "\n",
      "   type_['Pub', 'Casual Dining']  type_['Pub', 'Club']  \\\n",
      "0                              0                     0   \n",
      "0                              0                     0   \n",
      "0                              0                     0   \n",
      "0                              0                     0   \n",
      "1                              0                     0   \n",
      "\n",
      "   type_['Pub', 'Wine Bar']  type_['Pub']  type_['Wine Bar', 'Casual Dining']  \\\n",
      "0                         0             0                                   0   \n",
      "0                         0             0                                   0   \n",
      "0                         0             0                                   0   \n",
      "0                         0             0                                   0   \n",
      "1                         0             0                                   0   \n",
      "\n",
      "   type_['Wine Bar']  groupon_True  \n",
      "0                  0             0  \n",
      "0                  0             0  \n",
      "0                  0             0  \n",
      "0                  0             0  \n",
      "1                  0             0  \n",
      "\n",
      "[5 rows x 7623 columns]\n"
     ]
    }
   ],
   "source": [
    "# Display the cleaned and encoded Dataframe\n",
    "print(df_encoded.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63bbaab4",
   "metadata": {},
   "source": [
    "## II. Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00677546",
   "metadata": {},
   "source": [
    "### Model 1\n",
    "\n",
    "We built the linear regression model (model_regression_1) to predict the restaurant rating\n",
    "(numeric rating) from other features (columns) in the dataset. We used klearn.model_selection.train_test_split to split the data train (80%) and test (20%) sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c08ce406",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define X features and y target variable\n",
    "X = df_encoded.drop(columns=['rating_number'])  # All columns except rating_number\n",
    "y = df_encoded['rating_number']                  # Only rating_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "460a24b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "address                                object\n",
      "cost                                  float64\n",
      "lat                                   float64\n",
      "link                                   object\n",
      "lng                                   float64\n",
      "                                       ...   \n",
      "type_['Pub', 'Wine Bar']                uint8\n",
      "type_['Pub']                            uint8\n",
      "type_['Wine Bar', 'Casual Dining']      uint8\n",
      "type_['Wine Bar']                       uint8\n",
      "groupon_True                            uint8\n",
      "Length: 7622, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Check data types of columns\n",
    "print(X.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "fc296deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop irrelevant columns \n",
    "X = X.drop(columns=['address', 'link', 'phone', 'color', 'cuisine_color']) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "86ca5888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost                                  float64\n",
      "lat                                   float64\n",
      "lng                                   float64\n",
      "rating_text                             int32\n",
      "votes                                 float64\n",
      "                                       ...   \n",
      "type_['Pub', 'Wine Bar']                uint8\n",
      "type_['Pub']                            uint8\n",
      "type_['Wine Bar', 'Casual Dining']      uint8\n",
      "type_['Wine Bar']                       uint8\n",
      "groupon_True                            uint8\n",
      "Length: 7617, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(X.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a24a65",
   "metadata": {},
   "source": [
    "The Mean Squared Error (MSE) of 0.04 suggests that the model exhibits satisfactory performance, as it produces predictions that closely align with the actual values. Moreover, the R-squared value of 0.79 indicates that the model successfully explains 79% of the variance in the target variable, suggesting a strong correlation between the features and the predicted outcomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8c91ac8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.04\n",
      "R-squared: 0.79\n",
      "                                    Coefficient\n",
      "cost                                   0.000564\n",
      "lat                                    0.001354\n",
      "lng                                    0.000672\n",
      "rating_text                            0.171721\n",
      "votes                                  0.000752\n",
      "...                                         ...\n",
      "type_['Pub', 'Wine Bar']               0.110773\n",
      "type_['Pub']                          -0.124576\n",
      "type_['Wine Bar', 'Casual Dining']     0.075102\n",
      "type_['Wine Bar']                      0.019951\n",
      "groupon_True                          -0.064730\n",
      "\n",
      "[7617 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "# Split the data train (80%) and test (20%) sets.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Build the Linear Regression Model\n",
    "model_regression_1 = LinearRegression()\n",
    "model_regression_1.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model_regression_1.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Mean Squared Error: {mse:.2f}\")\n",
    "print(f\"R-squared: {r2:.2f}\")\n",
    "\n",
    "# Display coefficients\n",
    "coefficients = pd.DataFrame(model_regression_1.coef_, X.columns, columns=['Coefficient'])\n",
    "print(coefficients)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7a4e27",
   "metadata": {},
   "source": [
    "### Model 2 - Gradient Descent\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c07de7e",
   "metadata": {},
   "source": [
    "We built the linear regression model (model_regression_2) using SGDRegressor from sklearn.linear_model. This class implements linear regression with stochastic gradient descent. Similar to Model 1, we split the data into 80% train and 20% test sets. \n",
    "\n",
    "While our initial experiments with various learning rates (0.100, 0.010, 0.001, and 0.0001) led to satisfactory results with a learning rate of 0.0001 and a maximum iteration count of 1000, there remains a possibility of underfitting. The model's convergence at such a small learning rate suggests that it may not have fully explored the solution space, potentially limiting its ability to capture complex patterns in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d3874414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model 2 (Gradient Descent):\n",
      "Mean Squared Error: 0.05033288117242086\n",
      "R-squared: 0.7621679243616336\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Split the data into training (80%) and test (20%) sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# model_regression_2 = SGDRegressor(loss=\"squared_error\", max_iter=1000, random_state=0)\n",
    "model_regression_2 = SGDRegressor(loss=\"squared_error\", learning_rate='constant', eta0=0.0001, max_iter=1000, random_state=0)\n",
    "\n",
    "model_regression_2.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred_model2 = model_regression_2.predict(X_test_scaled)\n",
    "\n",
    "mse_model2 = mean_squared_error(y_test, y_pred_model2)\n",
    "r2_model2 = r2_score(y_test, y_pred_model2)\n",
    "\n",
    "print(f\"\\nModel 2 (Gradient Descent):\")\n",
    "print(f\"Mean Squared Error: {mse_model2}\")\n",
    "print(f\"R-squared: {r2_model2}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868a7c45",
   "metadata": {},
   "source": [
    "### Model 1 and Model 2 Comparison\n",
    "\n",
    "The results show that both Model 1 and Model 2 achieved strong performance in predicting the target variable. Model 1, with a Mean Squared Error of 0.04 and an R-squared of 0.79, demonstrated slightly better predictive accuracy compared to Model 2. Model 2 had a Mean Squared Error of 0.05 and an R-squared of 0.76."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41ea5a5",
   "metadata": {},
   "source": [
    "### III. Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d142dc2",
   "metadata": {},
   "source": [
    "We applied the Gradient Descent Logistic Regression used in Week 3 for the classification model. We simplified the problem into binary classifications where class 1 contains ‘Poor’ and\n",
    "‘Average’ records while class 2 contains ‘Good’, ‘Very Good’ and ‘Excellent’ records. We then dropped irrelevant columns and idenfied X and y for binary classification. We applied the sigmoid, optimize, and train_logistic_regression functions called from Week 3 lectures. \n",
    "\n",
    "The confusion matrix shows that the model correctly classified 15 instances as negative and 881 instances as positive. However, it also made a significant number of errors, incorrectly classifying 1380 instances as positive. The model did not miss any positive instances, but it did misclassify a large number of negative instances as positive, indicating a need for improvement in its ability to distinguish between the two classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "bdd3f08e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pauar\\AppData\\Local\\Temp\\ipykernel_20608\\700351840.py:39: RuntimeWarning: overflow encountered in exp\n",
      "  output = 1 / (1 + np.exp(-input))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[  15 1380]\n",
      " [   0  881]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "# Convert ratings to binary classes\n",
    "df_encoded['rating_text'] = df_encoded['rating_text'].map({\n",
    "    0: 1,  # 'Poor' -> class 1\n",
    "    1: 1,  # 'Average' -> class 1\n",
    "    2: 2,  # 'Good' -> class 2\n",
    "    3: 2,  # 'Very Good' -> class 2\n",
    "    4: 2   # 'Excellent' -> class 2\n",
    "})\n",
    "\n",
    "# Drop irrelevant columns\n",
    "irrelevant_columns = ['address', 'link', 'phone', 'color', 'cuisine_color']\n",
    "df_encoded_cleaned = df_encoded.drop(columns=irrelevant_columns)\n",
    "\n",
    "# Define X and y for the binary classification\n",
    "X = df_encoded_cleaned.drop(columns=['rating_number', 'rating_text']).values  # All columns except rating_number and rating_text\n",
    "y = df_encoded_cleaned['rating_text'].values  # Target variable\n",
    "\n",
    "# Split the data into training (80%) and test (20%) sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Initialize parameters for logistic regression\n",
    "init_parameters = {\n",
    "    \"weight\": np.zeros(X_train.shape[1]),  # Initialize weights as a NumPy array\n",
    "    \"bias\": 0  # Initialize bias\n",
    "}\n",
    "\n",
    "# Define the sigmoid function\n",
    "def sigmoid(input):    \n",
    "    output = 1 / (1 + np.exp(-input))\n",
    "    return output\n",
    "\n",
    "# Logistic regression optimization function\n",
    "def optimize(x, y, learning_rate, iterations, parameters): \n",
    "    size = x.shape[0]\n",
    "    weight = parameters[\"weight\"] \n",
    "    bias = parameters[\"bias\"]\n",
    "    \n",
    "    for i in range(iterations): \n",
    "        # Compute the linear combination\n",
    "        sigma = sigmoid(np.dot(x, weight) + bias)\n",
    "        # Calculate gradients\n",
    "        dW = 1/size * np.dot(x.T, (sigma - y))\n",
    "        db = 1/size * np.sum(sigma - y)\n",
    "        \n",
    "        # Update parameters\n",
    "        weight -= learning_rate * dW\n",
    "        bias -= learning_rate * db \n",
    "        \n",
    "    parameters[\"weight\"] = weight\n",
    "    parameters[\"bias\"] = bias\n",
    "    return parameters\n",
    "\n",
    "# Function to train logistic regression\n",
    "def train_logistic_regression(x, y, learning_rate, iterations):\n",
    "    parameters_out = optimize(x, y, learning_rate, iterations, init_parameters)\n",
    "    return parameters_out\n",
    "\n",
    "# Train the logistic regression model\n",
    "learning_rate = 0.02\n",
    "iterations = 5000\n",
    "trained_parameters = train_logistic_regression(X_train, y_train, learning_rate, iterations)\n",
    "\n",
    "# predict\n",
    "y_pred = np.dot(X_test, trained_parameters[\"weight\"]) + trained_parameters[\"bias\"]\n",
    "y_pred = sigmoid(y_pred)\n",
    "\n",
    "# Convert predictions to binary classes (1 or 2) \n",
    "y_pred = [2 if p >= 0.5 else 1 for p in y_pred]  \n",
    "\n",
    "# Evaluate the model using confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05991235",
   "metadata": {},
   "source": [
    "The confusion matrix shows that the model is very good at correctly identifying negative instances (1.00 accuracy), but it has a relatively high error rate for missing positive instances (0.01). This might indicate that the model is biased towards predicting negative instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4a280682",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualize confusion matrix with seaborn heatmap\n",
    "cm_normalised = cm.astype('float32') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "cm_matrix = pd.DataFrame(data=cm_normalised, columns=['Actual Positive:1', 'Actual Negative:0'], \n",
    "                                 index=['Predict Positive:1', 'Predict Negative:0'])\n",
    "\n",
    "sns.heatmap(cm_matrix, annot=True, fmt='.2f', cmap='YlGnBu')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89cb396",
   "metadata": {},
   "source": [
    "### Classification Task using Decision Tree, Random Forest, and Naive Bayes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2770780",
   "metadata": {},
   "source": [
    "Logistic Regression had many false positives (1380), while the others had fewer (Decision Tree: 95, Random Forest: 87, Gaussian Naive Bayes: 539). Decision Tree and Random Forest had similar numbers of false negatives (93 and 120), but Gaussian Naive Bayes had the fewest (23). Overall, Decision Tree and Random Forest performed the best, with high accuracy and low false positives and negatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3fb83077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: DecisionTreeClassifier\n",
      "Accuracy: 0.9174\n",
      "Confusion Matrix:\n",
      "[[1300   95]\n",
      " [  93  788]]\n",
      "\n",
      "Model: RandomForestClassifier\n",
      "Accuracy: 0.9091\n",
      "Confusion Matrix:\n",
      "[[1308   87]\n",
      " [ 120  761]]\n",
      "\n",
      "Model: GaussianNB\n",
      "Accuracy: 0.7531\n",
      "Confusion Matrix:\n",
      "[[856 539]\n",
      " [ 23 858]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7530755711775043,\n",
       " array([[856, 539],\n",
       "        [ 23, 858]], dtype=int64))"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Assuming df_encoded is your DataFrame\n",
    "# Convert ratings to binary classes\n",
    "df_encoded['rating_text'] = df_encoded['rating_text'].map({\n",
    "    0: 1,  # 'Poor' -> class 1\n",
    "    1: 1,  # 'Average' -> class 1\n",
    "    2: 2,  # 'Good' -> class 2\n",
    "    3: 2,  # 'Very Good' -> class 2\n",
    "    4: 2   # 'Excellent' -> class 2\n",
    "})\n",
    "\n",
    "# Drop irrelevant columns\n",
    "irrelevant_columns = ['address', 'link', 'phone', 'color', 'cuisine_color']\n",
    "df_encoded_cleaned = df_encoded.drop(columns=irrelevant_columns)\n",
    "\n",
    "# Define X and y for the binary classification\n",
    "X = df_encoded_cleaned.drop(columns=['rating_number', 'rating_text']).values  # All columns except rating_number and rating_text\n",
    "y = df_encoded_cleaned['rating_text'].values  # Target variable\n",
    "\n",
    "# Split the data into training (80%) and test (20%) sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Define a function to evaluate models\n",
    "def evaluate_model(model, X_train, X_test, y_train, y_test):\n",
    "    # Fit the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    print(f\"\\nModel: {model.__class__.__name__}\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(cm)\n",
    "    \n",
    "    return accuracy, cm\n",
    "\n",
    "# Decision Tree Classifier\n",
    "decision_tree = DecisionTreeClassifier(random_state=0)\n",
    "evaluate_model(decision_tree, X_train, X_test, y_train, y_test)\n",
    "\n",
    "# Random Forest Classifier\n",
    "random_forest = RandomForestClassifier(random_state=0, n_estimators=100)\n",
    "evaluate_model(random_forest, X_train, X_test, y_train, y_test)\n",
    "\n",
    "# Naive Bayes (GaussianNB)\n",
    "naive_bayes = GaussianNB()\n",
    "evaluate_model(naive_bayes, X_train, X_test, y_train, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590fcac3",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "This part of this assignment we compared the performance of two linear regression models and four classification models.\n",
    "\n",
    "For the linear regression task, both Model 1 and Model 2 achieved strong predictive accuracy, with Model 1 demonstrating slightly better performance based on the Mean Squared Error and R-squared metrics.\n",
    "\n",
    "For the classification task, Decision Tree and Random Forest classifiers emerged as the top-performing models. They exhibited significantly higher accuracy rates and effectively reduced the number of false positives compared to Logistic Regression and Gaussian Naive Bayes. While Gaussian Naive Bayes had the fewest false negatives, its overall accuracy was lower due to a higher number of false positives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f085e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
